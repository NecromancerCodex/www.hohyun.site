from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

from app.api.v1.routes import generate
from app.core.config import IMAGES_DIR, META_DIR

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Stable Diffusion SDXL API",
    description="RTX 4060 8GB ìµœì í™”ëœ SDXL ì´ë¯¸ì§€ ìƒì„± API",
    version="1.0.0",
)

# CORS ì„¤ì • - Next.jsì—ì„œ ì ‘ê·¼ í—ˆìš©
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5000",  # Next.js ê°œë°œ ì„œë²„
        "http://localhost:3000",  # ë‹¤ë¥¸ Next.js í¬íŠ¸
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(generate.router, prefix="/api/v1", tags=["Generate"])

# ì •ì  íŒŒì¼ ì„œë¹™ (ìƒì„±ëœ ì´ë¯¸ì§€)
IMAGES_DIR.mkdir(parents=True, exist_ok=True)
META_DIR.mkdir(parents=True, exist_ok=True)

app.mount("/outputs/images", StaticFiles(directory=str(IMAGES_DIR)), name="images")
app.mount("/outputs/metadata", StaticFiles(directory=str(META_DIR)), name="metadata")

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ í”„ë¦¬ë¡œë“œ (ì„ íƒì )"""
    print("=" * 60)
    print("ğŸš€ Stable Diffusion SDXL API ì‹œì‘")
    print(f"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ: {IMAGES_DIR}")
    print(f"ğŸ“ ë©”íƒ€ë°ì´í„° ì €ì¥ ê²½ë¡œ: {META_DIR}")
    print("=" * 60)
    
    # ì„ íƒ: ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ (ì²« ìš”ì²­ ì§€ì—° ë°©ì§€)
    # from .services.diffusion.pipeline_manager import get_pipeline
    # print("ğŸ”„ ëª¨ë¸ í”„ë¦¬ë¡œë”©...")
    # get_pipeline()
    # print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "message": "Stable Diffusion SDXL API is ready",
        "docs": "/docs",
    }

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    import torch
    return {
        "status": "healthy",
        "cuda_available": torch.cuda.is_available(),
        "cuda_device": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,
    }

