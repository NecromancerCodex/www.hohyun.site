{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 494,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004048582995951417,
      "grad_norm": 0.0,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.3317,
      "step": 1
    },
    {
      "epoch": 0.008097165991902834,
      "grad_norm": 0.0,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.2978,
      "step": 2
    },
    {
      "epoch": 0.012145748987854251,
      "grad_norm": 0.0,
      "learning_rate": 2.4e-05,
      "loss": 1.3281,
      "step": 3
    },
    {
      "epoch": 0.016194331983805668,
      "grad_norm": 0.0,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.3645,
      "step": 4
    },
    {
      "epoch": 0.020242914979757085,
      "grad_norm": 0.0,
      "learning_rate": 4e-05,
      "loss": 1.3528,
      "step": 5
    },
    {
      "epoch": 0.024291497975708502,
      "grad_norm": 0.0,
      "learning_rate": 4.8e-05,
      "loss": 1.3272,
      "step": 6
    },
    {
      "epoch": 0.02834008097165992,
      "grad_norm": 0.0,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 1.3524,
      "step": 7
    },
    {
      "epoch": 0.032388663967611336,
      "grad_norm": 0.0,
      "learning_rate": 6.400000000000001e-05,
      "loss": 1.3348,
      "step": 8
    },
    {
      "epoch": 0.03643724696356275,
      "grad_norm": 0.0,
      "learning_rate": 7.2e-05,
      "loss": 1.3225,
      "step": 9
    },
    {
      "epoch": 0.04048582995951417,
      "grad_norm": 0.0,
      "learning_rate": 8e-05,
      "loss": 1.3443,
      "step": 10
    },
    {
      "epoch": 0.044534412955465584,
      "grad_norm": 0.0,
      "learning_rate": 8.800000000000001e-05,
      "loss": 1.3253,
      "step": 11
    },
    {
      "epoch": 0.048582995951417005,
      "grad_norm": 0.0,
      "learning_rate": 9.6e-05,
      "loss": 1.2742,
      "step": 12
    },
    {
      "epoch": 0.05263157894736842,
      "grad_norm": 0.0,
      "learning_rate": 0.00010400000000000001,
      "loss": 1.3075,
      "step": 13
    },
    {
      "epoch": 0.05668016194331984,
      "grad_norm": 0.0,
      "learning_rate": 0.00011200000000000001,
      "loss": 1.3006,
      "step": 14
    },
    {
      "epoch": 0.06072874493927125,
      "grad_norm": 0.0,
      "learning_rate": 0.00012,
      "loss": 1.3028,
      "step": 15
    },
    {
      "epoch": 0.06477732793522267,
      "grad_norm": 0.0,
      "learning_rate": 0.00012800000000000002,
      "loss": 1.2884,
      "step": 16
    },
    {
      "epoch": 0.06882591093117409,
      "grad_norm": 0.0,
      "learning_rate": 0.00013600000000000003,
      "loss": 1.3053,
      "step": 17
    },
    {
      "epoch": 0.0728744939271255,
      "grad_norm": 0.0,
      "learning_rate": 0.000144,
      "loss": 1.269,
      "step": 18
    },
    {
      "epoch": 0.07692307692307693,
      "grad_norm": 0.0,
      "learning_rate": 0.000152,
      "loss": 1.2712,
      "step": 19
    },
    {
      "epoch": 0.08097165991902834,
      "grad_norm": 0.0,
      "learning_rate": 0.00016,
      "loss": 1.2883,
      "step": 20
    },
    {
      "epoch": 0.08502024291497975,
      "grad_norm": 0.0,
      "learning_rate": 0.000168,
      "loss": 1.2264,
      "step": 21
    },
    {
      "epoch": 0.08906882591093117,
      "grad_norm": 0.0,
      "learning_rate": 0.00017600000000000002,
      "loss": 1.2394,
      "step": 22
    },
    {
      "epoch": 0.0931174089068826,
      "grad_norm": 0.0,
      "learning_rate": 0.00018400000000000003,
      "loss": 1.2205,
      "step": 23
    },
    {
      "epoch": 0.09716599190283401,
      "grad_norm": 0.0,
      "learning_rate": 0.000192,
      "loss": 1.2784,
      "step": 24
    },
    {
      "epoch": 0.10121457489878542,
      "grad_norm": 0.0,
      "learning_rate": 0.0002,
      "loss": 1.2484,
      "step": 25
    },
    {
      "epoch": 0.10526315789473684,
      "grad_norm": 0.0,
      "learning_rate": 0.00019999775651876987,
      "loss": 1.2147,
      "step": 26
    },
    {
      "epoch": 0.10931174089068826,
      "grad_norm": 0.0,
      "learning_rate": 0.00019999102617574365,
      "loss": 1.2408,
      "step": 27
    },
    {
      "epoch": 0.11336032388663968,
      "grad_norm": 0.0,
      "learning_rate": 0.00019997980927290927,
      "loss": 1.2207,
      "step": 28
    },
    {
      "epoch": 0.11740890688259109,
      "grad_norm": 0.0,
      "learning_rate": 0.00019996410631356498,
      "loss": 1.2061,
      "step": 29
    },
    {
      "epoch": 0.1214574898785425,
      "grad_norm": 0.0,
      "learning_rate": 0.00019994391800229666,
      "loss": 1.2239,
      "step": 30
    },
    {
      "epoch": 0.12550607287449392,
      "grad_norm": 0.0,
      "learning_rate": 0.00019991924524494627,
      "loss": 1.196,
      "step": 31
    },
    {
      "epoch": 0.12955465587044535,
      "grad_norm": 0.0,
      "learning_rate": 0.00019989008914857116,
      "loss": 1.2056,
      "step": 32
    },
    {
      "epoch": 0.13360323886639677,
      "grad_norm": 0.0,
      "learning_rate": 0.0001998564510213944,
      "loss": 1.1465,
      "step": 33
    },
    {
      "epoch": 0.13765182186234817,
      "grad_norm": 0.0,
      "learning_rate": 0.00019981833237274618,
      "loss": 1.1907,
      "step": 34
    },
    {
      "epoch": 0.1417004048582996,
      "grad_norm": 0.0,
      "learning_rate": 0.00019977573491299598,
      "loss": 1.1834,
      "step": 35
    },
    {
      "epoch": 0.145748987854251,
      "grad_norm": 0.0,
      "learning_rate": 0.00019972866055347572,
      "loss": 1.1527,
      "step": 36
    },
    {
      "epoch": 0.14979757085020243,
      "grad_norm": 0.0,
      "learning_rate": 0.0001996771114063943,
      "loss": 1.1677,
      "step": 37
    },
    {
      "epoch": 0.15384615384615385,
      "grad_norm": 0.0,
      "learning_rate": 0.00019962108978474263,
      "loss": 1.1825,
      "step": 38
    },
    {
      "epoch": 0.15789473684210525,
      "grad_norm": 0.0,
      "learning_rate": 0.00019956059820218982,
      "loss": 1.1529,
      "step": 39
    },
    {
      "epoch": 0.16194331983805668,
      "grad_norm": 0.0,
      "learning_rate": 0.00019949563937297045,
      "loss": 1.1664,
      "step": 40
    },
    {
      "epoch": 0.1659919028340081,
      "grad_norm": 0.0,
      "learning_rate": 0.00019942621621176282,
      "loss": 1.1635,
      "step": 41
    },
    {
      "epoch": 0.1700404858299595,
      "grad_norm": 0.0,
      "learning_rate": 0.0001993523318335581,
      "loss": 1.1193,
      "step": 42
    },
    {
      "epoch": 0.17408906882591094,
      "grad_norm": 0.0,
      "learning_rate": 0.00019927398955352061,
      "loss": 1.167,
      "step": 43
    },
    {
      "epoch": 0.17813765182186234,
      "grad_norm": 0.0,
      "learning_rate": 0.00019919119288683908,
      "loss": 1.1568,
      "step": 44
    },
    {
      "epoch": 0.18218623481781376,
      "grad_norm": 0.0,
      "learning_rate": 0.00019910394554856876,
      "loss": 1.1376,
      "step": 45
    },
    {
      "epoch": 0.1862348178137652,
      "grad_norm": 0.0,
      "learning_rate": 0.0001990122514534651,
      "loss": 1.1422,
      "step": 46
    },
    {
      "epoch": 0.1902834008097166,
      "grad_norm": 0.0,
      "learning_rate": 0.00019891611471580764,
      "loss": 1.1757,
      "step": 47
    },
    {
      "epoch": 0.19433198380566802,
      "grad_norm": 0.0,
      "learning_rate": 0.00019881553964921572,
      "loss": 1.1157,
      "step": 48
    },
    {
      "epoch": 0.19838056680161945,
      "grad_norm": 0.0,
      "learning_rate": 0.00019871053076645488,
      "loss": 1.1522,
      "step": 49
    },
    {
      "epoch": 0.20242914979757085,
      "grad_norm": 0.0,
      "learning_rate": 0.00019860109277923418,
      "loss": 1.1093,
      "step": 50
    },
    {
      "epoch": 0.20647773279352227,
      "grad_norm": 0.0,
      "learning_rate": 0.00019848723059799506,
      "loss": 1.1341,
      "step": 51
    },
    {
      "epoch": 0.21052631578947367,
      "grad_norm": 0.0,
      "learning_rate": 0.00019836894933169088,
      "loss": 1.1087,
      "step": 52
    },
    {
      "epoch": 0.2145748987854251,
      "grad_norm": 0.0,
      "learning_rate": 0.0001982462542875576,
      "loss": 1.1469,
      "step": 53
    },
    {
      "epoch": 0.21862348178137653,
      "grad_norm": 0.0,
      "learning_rate": 0.00019811915097087587,
      "loss": 1.1397,
      "step": 54
    },
    {
      "epoch": 0.22267206477732793,
      "grad_norm": 0.0,
      "learning_rate": 0.00019798764508472373,
      "loss": 1.0972,
      "step": 55
    },
    {
      "epoch": 0.22672064777327935,
      "grad_norm": 0.0,
      "learning_rate": 0.00019785174252972092,
      "loss": 1.0941,
      "step": 56
    },
    {
      "epoch": 0.23076923076923078,
      "grad_norm": 0.0,
      "learning_rate": 0.0001977114494037641,
      "loss": 1.1109,
      "step": 57
    },
    {
      "epoch": 0.23481781376518218,
      "grad_norm": 0.0,
      "learning_rate": 0.00019756677200175315,
      "loss": 1.0792,
      "step": 58
    },
    {
      "epoch": 0.2388663967611336,
      "grad_norm": 0.0,
      "learning_rate": 0.0001974177168153088,
      "loss": 1.1418,
      "step": 59
    },
    {
      "epoch": 0.242914979757085,
      "grad_norm": 0.0,
      "learning_rate": 0.0001972642905324813,
      "loss": 1.1654,
      "step": 60
    },
    {
      "epoch": 0.24696356275303644,
      "grad_norm": 0.0,
      "learning_rate": 0.0001971065000374504,
      "loss": 1.1004,
      "step": 61
    },
    {
      "epoch": 0.25101214574898784,
      "grad_norm": 0.0,
      "learning_rate": 0.0001969443524102163,
      "loss": 1.074,
      "step": 62
    },
    {
      "epoch": 0.2550607287449393,
      "grad_norm": 0.0,
      "learning_rate": 0.0001967778549262822,
      "loss": 1.1251,
      "step": 63
    },
    {
      "epoch": 0.2591093117408907,
      "grad_norm": 0.0,
      "learning_rate": 0.00019660701505632772,
      "loss": 1.0892,
      "step": 64
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 0.0,
      "learning_rate": 0.0001964318404658737,
      "loss": 1.1376,
      "step": 65
    },
    {
      "epoch": 0.26720647773279355,
      "grad_norm": 0.0,
      "learning_rate": 0.00019625233901493822,
      "loss": 1.0612,
      "step": 66
    },
    {
      "epoch": 0.27125506072874495,
      "grad_norm": 0.0,
      "learning_rate": 0.000196068518757684,
      "loss": 1.1087,
      "step": 67
    },
    {
      "epoch": 0.27530364372469635,
      "grad_norm": 0.0,
      "learning_rate": 0.00019588038794205703,
      "loss": 1.115,
      "step": 68
    },
    {
      "epoch": 0.2793522267206478,
      "grad_norm": 0.0,
      "learning_rate": 0.00019568795500941635,
      "loss": 1.101,
      "step": 69
    },
    {
      "epoch": 0.2834008097165992,
      "grad_norm": 0.0,
      "learning_rate": 0.00019549122859415538,
      "loss": 1.0784,
      "step": 70
    },
    {
      "epoch": 0.2874493927125506,
      "grad_norm": 0.0,
      "learning_rate": 0.00019529021752331453,
      "loss": 1.1057,
      "step": 71
    },
    {
      "epoch": 0.291497975708502,
      "grad_norm": 0.0,
      "learning_rate": 0.00019508493081618513,
      "loss": 1.0948,
      "step": 72
    },
    {
      "epoch": 0.29554655870445345,
      "grad_norm": 0.0,
      "learning_rate": 0.00019487537768390464,
      "loss": 1.1183,
      "step": 73
    },
    {
      "epoch": 0.29959514170040485,
      "grad_norm": 0.0,
      "learning_rate": 0.00019466156752904343,
      "loss": 1.1001,
      "step": 74
    },
    {
      "epoch": 0.30364372469635625,
      "grad_norm": 0.0,
      "learning_rate": 0.0001944435099451829,
      "loss": 1.0723,
      "step": 75
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 0.0,
      "learning_rate": 0.00019422121471648497,
      "loss": 1.0729,
      "step": 76
    },
    {
      "epoch": 0.3117408906882591,
      "grad_norm": 0.0,
      "learning_rate": 0.0001939946918172531,
      "loss": 1.0615,
      "step": 77
    },
    {
      "epoch": 0.3157894736842105,
      "grad_norm": 0.0,
      "learning_rate": 0.00019376395141148476,
      "loss": 1.0635,
      "step": 78
    },
    {
      "epoch": 0.31983805668016196,
      "grad_norm": 0.0,
      "learning_rate": 0.00019352900385241536,
      "loss": 1.0984,
      "step": 79
    },
    {
      "epoch": 0.32388663967611336,
      "grad_norm": 0.0,
      "learning_rate": 0.0001932898596820536,
      "loss": 1.084,
      "step": 80
    },
    {
      "epoch": 0.32793522267206476,
      "grad_norm": 0.0,
      "learning_rate": 0.0001930465296307087,
      "loss": 1.0703,
      "step": 81
    },
    {
      "epoch": 0.3319838056680162,
      "grad_norm": 0.0,
      "learning_rate": 0.00019279902461650866,
      "loss": 1.0835,
      "step": 82
    },
    {
      "epoch": 0.3360323886639676,
      "grad_norm": 0.0,
      "learning_rate": 0.00019254735574491058,
      "loss": 1.0518,
      "step": 83
    },
    {
      "epoch": 0.340080971659919,
      "grad_norm": 0.0,
      "learning_rate": 0.00019229153430820232,
      "loss": 1.0814,
      "step": 84
    },
    {
      "epoch": 0.3441295546558704,
      "grad_norm": 0.0,
      "learning_rate": 0.0001920315717849956,
      "loss": 1.0525,
      "step": 85
    },
    {
      "epoch": 0.3481781376518219,
      "grad_norm": 0.0,
      "learning_rate": 0.0001917674798397113,
      "loss": 1.0678,
      "step": 86
    },
    {
      "epoch": 0.3522267206477733,
      "grad_norm": 0.0,
      "learning_rate": 0.00019149927032205587,
      "loss": 1.0756,
      "step": 87
    },
    {
      "epoch": 0.3562753036437247,
      "grad_norm": 0.0,
      "learning_rate": 0.00019122695526648968,
      "loss": 1.0319,
      "step": 88
    },
    {
      "epoch": 0.3603238866396761,
      "grad_norm": 0.0,
      "learning_rate": 0.00019095054689168705,
      "loss": 1.0666,
      "step": 89
    },
    {
      "epoch": 0.3643724696356275,
      "grad_norm": 0.0,
      "learning_rate": 0.00019067005759998797,
      "loss": 1.0309,
      "step": 90
    },
    {
      "epoch": 0.3684210526315789,
      "grad_norm": 0.0,
      "learning_rate": 0.0001903854999768417,
      "loss": 1.0896,
      "step": 91
    },
    {
      "epoch": 0.3724696356275304,
      "grad_norm": 0.0,
      "learning_rate": 0.0001900968867902419,
      "loss": 1.0868,
      "step": 92
    },
    {
      "epoch": 0.3765182186234818,
      "grad_norm": 0.0,
      "learning_rate": 0.00018980423099015402,
      "loss": 1.07,
      "step": 93
    },
    {
      "epoch": 0.3805668016194332,
      "grad_norm": 0.0,
      "learning_rate": 0.00018950754570793384,
      "loss": 1.0437,
      "step": 94
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 0.0,
      "learning_rate": 0.00018920684425573865,
      "loss": 1.0558,
      "step": 95
    },
    {
      "epoch": 0.38866396761133604,
      "grad_norm": 0.0,
      "learning_rate": 0.00018890214012592975,
      "loss": 1.0847,
      "step": 96
    },
    {
      "epoch": 0.39271255060728744,
      "grad_norm": 0.0,
      "learning_rate": 0.000188593446990467,
      "loss": 1.0651,
      "step": 97
    },
    {
      "epoch": 0.3967611336032389,
      "grad_norm": 0.0,
      "learning_rate": 0.00018828077870029552,
      "loss": 1.0605,
      "step": 98
    },
    {
      "epoch": 0.4008097165991903,
      "grad_norm": 0.0,
      "learning_rate": 0.00018796414928472417,
      "loss": 1.0717,
      "step": 99
    },
    {
      "epoch": 0.4048582995951417,
      "grad_norm": 0.0,
      "learning_rate": 0.0001876435729507959,
      "loss": 1.0472,
      "step": 100
    },
    {
      "epoch": 0.4089068825910931,
      "grad_norm": 0.0,
      "learning_rate": 0.0001873190640826505,
      "loss": 1.0702,
      "step": 101
    },
    {
      "epoch": 0.41295546558704455,
      "grad_norm": 0.0,
      "learning_rate": 0.00018699063724087904,
      "loss": 1.024,
      "step": 102
    },
    {
      "epoch": 0.41700404858299595,
      "grad_norm": 0.0,
      "learning_rate": 0.00018665830716187065,
      "loss": 1.0162,
      "step": 103
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 0.0,
      "learning_rate": 0.0001863220887571512,
      "loss": 1.0504,
      "step": 104
    },
    {
      "epoch": 0.4251012145748988,
      "grad_norm": 0.0,
      "learning_rate": 0.0001859819971127143,
      "loss": 1.0588,
      "step": 105
    },
    {
      "epoch": 0.4291497975708502,
      "grad_norm": 0.0,
      "learning_rate": 0.00018563804748834438,
      "loss": 1.0377,
      "step": 106
    },
    {
      "epoch": 0.4331983805668016,
      "grad_norm": 0.0,
      "learning_rate": 0.000185290255316932,
      "loss": 1.0385,
      "step": 107
    },
    {
      "epoch": 0.43724696356275305,
      "grad_norm": 0.0,
      "learning_rate": 0.00018493863620378122,
      "loss": 1.0031,
      "step": 108
    },
    {
      "epoch": 0.44129554655870445,
      "grad_norm": 0.0,
      "learning_rate": 0.00018458320592590975,
      "loss": 1.0374,
      "step": 109
    },
    {
      "epoch": 0.44534412955465585,
      "grad_norm": 0.0,
      "learning_rate": 0.00018422398043134067,
      "loss": 1.0001,
      "step": 110
    },
    {
      "epoch": 0.4493927125506073,
      "grad_norm": 0.0,
      "learning_rate": 0.00018386097583838714,
      "loss": 1.0206,
      "step": 111
    },
    {
      "epoch": 0.4534412955465587,
      "grad_norm": 0.0,
      "learning_rate": 0.00018349420843492888,
      "loss": 1.0297,
      "step": 112
    },
    {
      "epoch": 0.4574898785425101,
      "grad_norm": 0.0,
      "learning_rate": 0.00018312369467768166,
      "loss": 1.0314,
      "step": 113
    },
    {
      "epoch": 0.46153846153846156,
      "grad_norm": 0.0,
      "learning_rate": 0.0001827494511914587,
      "loss": 1.0102,
      "step": 114
    },
    {
      "epoch": 0.46558704453441296,
      "grad_norm": 0.0,
      "learning_rate": 0.0001823714947684247,
      "loss": 1.0385,
      "step": 115
    },
    {
      "epoch": 0.46963562753036436,
      "grad_norm": 0.0,
      "learning_rate": 0.00018198984236734246,
      "loss": 1.0349,
      "step": 116
    },
    {
      "epoch": 0.47368421052631576,
      "grad_norm": 0.0,
      "learning_rate": 0.000181604511112812,
      "loss": 1.0241,
      "step": 117
    },
    {
      "epoch": 0.4777327935222672,
      "grad_norm": 0.0,
      "learning_rate": 0.000181215518294502,
      "loss": 1.0459,
      "step": 118
    },
    {
      "epoch": 0.4817813765182186,
      "grad_norm": 0.0,
      "learning_rate": 0.00018082288136637422,
      "loss": 1.0141,
      "step": 119
    },
    {
      "epoch": 0.48582995951417,
      "grad_norm": 0.0,
      "learning_rate": 0.00018042661794590023,
      "loss": 1.0061,
      "step": 120
    },
    {
      "epoch": 0.4898785425101215,
      "grad_norm": 0.0,
      "learning_rate": 0.00018002674581327094,
      "loss": 0.9931,
      "step": 121
    },
    {
      "epoch": 0.4939271255060729,
      "grad_norm": 0.0,
      "learning_rate": 0.00017962328291059888,
      "loss": 1.0376,
      "step": 122
    },
    {
      "epoch": 0.4979757085020243,
      "grad_norm": 0.0,
      "learning_rate": 0.00017921624734111292,
      "loss": 1.0218,
      "step": 123
    },
    {
      "epoch": 0.5020242914979757,
      "grad_norm": 0.0,
      "learning_rate": 0.0001788056573683464,
      "loss": 1.0364,
      "step": 124
    },
    {
      "epoch": 0.5060728744939271,
      "grad_norm": 0.0,
      "learning_rate": 0.00017839153141531718,
      "loss": 1.0096,
      "step": 125
    },
    {
      "epoch": 0.5101214574898786,
      "grad_norm": 0.0,
      "learning_rate": 0.00017797388806370132,
      "loss": 1.0217,
      "step": 126
    },
    {
      "epoch": 0.5141700404858299,
      "grad_norm": 0.0,
      "learning_rate": 0.00017755274605299923,
      "loss": 0.9984,
      "step": 127
    },
    {
      "epoch": 0.5182186234817814,
      "grad_norm": 0.0,
      "learning_rate": 0.00017712812427969485,
      "loss": 1.0305,
      "step": 128
    },
    {
      "epoch": 0.5222672064777328,
      "grad_norm": 0.0,
      "learning_rate": 0.00017670004179640774,
      "loss": 1.0196,
      "step": 129
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 0.0,
      "learning_rate": 0.0001762685178110382,
      "loss": 0.976,
      "step": 130
    },
    {
      "epoch": 0.5303643724696356,
      "grad_norm": 0.0,
      "learning_rate": 0.0001758335716859055,
      "loss": 1.0015,
      "step": 131
    },
    {
      "epoch": 0.5344129554655871,
      "grad_norm": 0.0,
      "learning_rate": 0.00017539522293687898,
      "loss": 1.0391,
      "step": 132
    },
    {
      "epoch": 0.5384615384615384,
      "grad_norm": 0.0,
      "learning_rate": 0.00017495349123250242,
      "loss": 1.0243,
      "step": 133
    },
    {
      "epoch": 0.5425101214574899,
      "grad_norm": 0.0,
      "learning_rate": 0.00017450839639311162,
      "loss": 1.0226,
      "step": 134
    },
    {
      "epoch": 0.5465587044534413,
      "grad_norm": 0.0,
      "learning_rate": 0.00017405995838994494,
      "loss": 1.0355,
      "step": 135
    },
    {
      "epoch": 0.5506072874493927,
      "grad_norm": 0.0,
      "learning_rate": 0.00017360819734424715,
      "loss": 1.0354,
      "step": 136
    },
    {
      "epoch": 0.5546558704453441,
      "grad_norm": 0.0,
      "learning_rate": 0.0001731531335263669,
      "loss": 1.0206,
      "step": 137
    },
    {
      "epoch": 0.5587044534412956,
      "grad_norm": 0.0,
      "learning_rate": 0.00017269478735484683,
      "loss": 1.023,
      "step": 138
    },
    {
      "epoch": 0.562753036437247,
      "grad_norm": 0.0,
      "learning_rate": 0.00017223317939550753,
      "loss": 0.9907,
      "step": 139
    },
    {
      "epoch": 0.5668016194331984,
      "grad_norm": 0.0,
      "learning_rate": 0.00017176833036052495,
      "loss": 1.0207,
      "step": 140
    },
    {
      "epoch": 0.5708502024291497,
      "grad_norm": 0.0,
      "learning_rate": 0.0001713002611075007,
      "loss": 0.9978,
      "step": 141
    },
    {
      "epoch": 0.5748987854251012,
      "grad_norm": 0.0,
      "learning_rate": 0.0001708289926385265,
      "loss": 1.0292,
      "step": 142
    },
    {
      "epoch": 0.5789473684210527,
      "grad_norm": 0.0,
      "learning_rate": 0.0001703545460992416,
      "loss": 1.0062,
      "step": 143
    },
    {
      "epoch": 0.582995951417004,
      "grad_norm": 0.0,
      "learning_rate": 0.00016987694277788417,
      "loss": 1.0625,
      "step": 144
    },
    {
      "epoch": 0.5870445344129555,
      "grad_norm": 0.0,
      "learning_rate": 0.0001693962041043359,
      "loss": 1.0001,
      "step": 145
    },
    {
      "epoch": 0.5910931174089069,
      "grad_norm": 0.0,
      "learning_rate": 0.00016891235164916065,
      "loss": 1.0056,
      "step": 146
    },
    {
      "epoch": 0.5951417004048583,
      "grad_norm": 0.0,
      "learning_rate": 0.00016842540712263637,
      "loss": 1.0331,
      "step": 147
    },
    {
      "epoch": 0.5991902834008097,
      "grad_norm": 0.0,
      "learning_rate": 0.00016793539237378128,
      "loss": 0.984,
      "step": 148
    },
    {
      "epoch": 0.6032388663967612,
      "grad_norm": 0.0,
      "learning_rate": 0.00016744232938937308,
      "loss": 1.0204,
      "step": 149
    },
    {
      "epoch": 0.6072874493927125,
      "grad_norm": 0.0,
      "learning_rate": 0.0001669462402929629,
      "loss": 1.0269,
      "step": 150
    },
    {
      "epoch": 0.611336032388664,
      "grad_norm": 0.0,
      "learning_rate": 0.00016644714734388217,
      "loss": 1.0477,
      "step": 151
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 0.0,
      "learning_rate": 0.00016594507293624425,
      "loss": 1.0223,
      "step": 152
    },
    {
      "epoch": 0.6194331983805668,
      "grad_norm": 0.0,
      "learning_rate": 0.00016544003959793925,
      "loss": 1.0217,
      "step": 153
    },
    {
      "epoch": 0.6234817813765182,
      "grad_norm": 0.0,
      "learning_rate": 0.00016493206998962354,
      "loss": 1.0026,
      "step": 154
    },
    {
      "epoch": 0.6275303643724697,
      "grad_norm": 0.0,
      "learning_rate": 0.0001644211869037027,
      "loss": 0.9742,
      "step": 155
    },
    {
      "epoch": 0.631578947368421,
      "grad_norm": 0.0,
      "learning_rate": 0.00016390741326330907,
      "loss": 0.9803,
      "step": 156
    },
    {
      "epoch": 0.6356275303643725,
      "grad_norm": 0.0,
      "learning_rate": 0.00016339077212127294,
      "loss": 1.0126,
      "step": 157
    },
    {
      "epoch": 0.6396761133603239,
      "grad_norm": 0.0,
      "learning_rate": 0.0001628712866590885,
      "loss": 1.0253,
      "step": 158
    },
    {
      "epoch": 0.6437246963562753,
      "grad_norm": 0.0,
      "learning_rate": 0.00016234898018587337,
      "loss": 1.0047,
      "step": 159
    },
    {
      "epoch": 0.6477732793522267,
      "grad_norm": 0.0,
      "learning_rate": 0.00016182387613732291,
      "loss": 0.9986,
      "step": 160
    },
    {
      "epoch": 0.6518218623481782,
      "grad_norm": 0.0,
      "learning_rate": 0.00016129599807465875,
      "loss": 1.0011,
      "step": 161
    },
    {
      "epoch": 0.6558704453441295,
      "grad_norm": 0.0,
      "learning_rate": 0.0001607653696835713,
      "loss": 0.9783,
      "step": 162
    },
    {
      "epoch": 0.659919028340081,
      "grad_norm": 0.0,
      "learning_rate": 0.00016023201477315731,
      "loss": 1.0145,
      "step": 163
    },
    {
      "epoch": 0.6639676113360324,
      "grad_norm": 0.0,
      "learning_rate": 0.0001596959572748514,
      "loss": 1.0195,
      "step": 164
    },
    {
      "epoch": 0.6680161943319838,
      "grad_norm": 0.0,
      "learning_rate": 0.00015915722124135227,
      "loss": 1.0198,
      "step": 165
    },
    {
      "epoch": 0.6720647773279352,
      "grad_norm": 0.0,
      "learning_rate": 0.00015861583084554349,
      "loss": 0.9749,
      "step": 166
    },
    {
      "epoch": 0.6761133603238867,
      "grad_norm": 0.0,
      "learning_rate": 0.0001580718103794089,
      "loss": 0.9962,
      "step": 167
    },
    {
      "epoch": 0.680161943319838,
      "grad_norm": 0.0,
      "learning_rate": 0.00015752518425294257,
      "loss": 1.0021,
      "step": 168
    },
    {
      "epoch": 0.6842105263157895,
      "grad_norm": 0.0,
      "learning_rate": 0.00015697597699305366,
      "loss": 0.982,
      "step": 169
    },
    {
      "epoch": 0.6882591093117408,
      "grad_norm": 0.0,
      "learning_rate": 0.00015642421324246568,
      "loss": 0.9877,
      "step": 170
    },
    {
      "epoch": 0.6923076923076923,
      "grad_norm": 0.0,
      "learning_rate": 0.00015586991775861102,
      "loss": 0.9625,
      "step": 171
    },
    {
      "epoch": 0.6963562753036437,
      "grad_norm": 0.0,
      "learning_rate": 0.00015531311541251995,
      "loss": 1.0116,
      "step": 172
    },
    {
      "epoch": 0.7004048582995951,
      "grad_norm": 0.0,
      "learning_rate": 0.00015475383118770472,
      "loss": 0.9607,
      "step": 173
    },
    {
      "epoch": 0.7044534412955465,
      "grad_norm": 0.0,
      "learning_rate": 0.00015419209017903852,
      "loss": 0.9899,
      "step": 174
    },
    {
      "epoch": 0.708502024291498,
      "grad_norm": 0.0,
      "learning_rate": 0.0001536279175916296,
      "loss": 1.0611,
      "step": 175
    },
    {
      "epoch": 0.7125506072874493,
      "grad_norm": 0.0,
      "learning_rate": 0.0001530613387396901,
      "loss": 0.9796,
      "step": 176
    },
    {
      "epoch": 0.7165991902834008,
      "grad_norm": 0.0,
      "learning_rate": 0.0001524923790454004,
      "loss": 1.0002,
      "step": 177
    },
    {
      "epoch": 0.7206477732793523,
      "grad_norm": 0.0,
      "learning_rate": 0.00015192106403776848,
      "loss": 0.9898,
      "step": 178
    },
    {
      "epoch": 0.7246963562753036,
      "grad_norm": 0.0,
      "learning_rate": 0.0001513474193514842,
      "loss": 1.0209,
      "step": 179
    },
    {
      "epoch": 0.728744939271255,
      "grad_norm": 0.0,
      "learning_rate": 0.00015077147072576933,
      "loss": 1.0319,
      "step": 180
    },
    {
      "epoch": 0.7327935222672065,
      "grad_norm": 0.0,
      "learning_rate": 0.00015019324400322243,
      "loss": 0.9751,
      "step": 181
    },
    {
      "epoch": 0.7368421052631579,
      "grad_norm": 0.0,
      "learning_rate": 0.00014961276512865954,
      "loss": 0.9693,
      "step": 182
    },
    {
      "epoch": 0.7408906882591093,
      "grad_norm": 0.0,
      "learning_rate": 0.00014903006014794983,
      "loss": 0.9838,
      "step": 183
    },
    {
      "epoch": 0.7449392712550608,
      "grad_norm": 0.0,
      "learning_rate": 0.00014844515520684703,
      "loss": 1.0159,
      "step": 184
    },
    {
      "epoch": 0.7489878542510121,
      "grad_norm": 0.0,
      "learning_rate": 0.00014785807654981627,
      "loss": 1.0361,
      "step": 185
    },
    {
      "epoch": 0.7530364372469636,
      "grad_norm": 0.0,
      "learning_rate": 0.00014726885051885653,
      "loss": 0.9602,
      "step": 186
    },
    {
      "epoch": 0.757085020242915,
      "grad_norm": 0.0,
      "learning_rate": 0.0001466775035523186,
      "loss": 0.968,
      "step": 187
    },
    {
      "epoch": 0.7611336032388664,
      "grad_norm": 0.0,
      "learning_rate": 0.00014608406218371894,
      "loss": 1.0053,
      "step": 188
    },
    {
      "epoch": 0.7651821862348178,
      "grad_norm": 0.0,
      "learning_rate": 0.00014548855304054886,
      "loss": 1.025,
      "step": 189
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.0,
      "learning_rate": 0.00014489100284308017,
      "loss": 0.9322,
      "step": 190
    },
    {
      "epoch": 0.7732793522267206,
      "grad_norm": 0.0,
      "learning_rate": 0.00014429143840316585,
      "loss": 1.0204,
      "step": 191
    },
    {
      "epoch": 0.7773279352226721,
      "grad_norm": 0.0,
      "learning_rate": 0.00014368988662303732,
      "loss": 0.9984,
      "step": 192
    },
    {
      "epoch": 0.7813765182186235,
      "grad_norm": 0.0,
      "learning_rate": 0.00014308637449409706,
      "loss": 1.0237,
      "step": 193
    },
    {
      "epoch": 0.7854251012145749,
      "grad_norm": 0.0,
      "learning_rate": 0.00014248092909570774,
      "loss": 0.9797,
      "step": 194
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 0.0,
      "learning_rate": 0.00014187357759397714,
      "loss": 0.9901,
      "step": 195
    },
    {
      "epoch": 0.7935222672064778,
      "grad_norm": 0.0,
      "learning_rate": 0.00014126434724053913,
      "loss": 0.9659,
      "step": 196
    },
    {
      "epoch": 0.7975708502024291,
      "grad_norm": 0.0,
      "learning_rate": 0.00014065326537133094,
      "loss": 0.9847,
      "step": 197
    },
    {
      "epoch": 0.8016194331983806,
      "grad_norm": 0.0,
      "learning_rate": 0.0001400403594053667,
      "loss": 0.9878,
      "step": 198
    },
    {
      "epoch": 0.805668016194332,
      "grad_norm": 0.0,
      "learning_rate": 0.00013942565684350698,
      "loss": 0.9626,
      "step": 199
    },
    {
      "epoch": 0.8097165991902834,
      "grad_norm": 0.0,
      "learning_rate": 0.00013880918526722497,
      "loss": 0.9457,
      "step": 200
    },
    {
      "epoch": 0.8137651821862348,
      "grad_norm": 0.0,
      "learning_rate": 0.00013819097233736888,
      "loss": 0.959,
      "step": 201
    },
    {
      "epoch": 0.8178137651821862,
      "grad_norm": 0.0,
      "learning_rate": 0.00013757104579292082,
      "loss": 0.9702,
      "step": 202
    },
    {
      "epoch": 0.8218623481781376,
      "grad_norm": 0.0,
      "learning_rate": 0.00013694943344975212,
      "loss": 0.9824,
      "step": 203
    },
    {
      "epoch": 0.8259109311740891,
      "grad_norm": 0.0,
      "learning_rate": 0.00013632616319937522,
      "loss": 0.9589,
      "step": 204
    },
    {
      "epoch": 0.8299595141700404,
      "grad_norm": 0.0,
      "learning_rate": 0.00013570126300769232,
      "loss": 0.9761,
      "step": 205
    },
    {
      "epoch": 0.8340080971659919,
      "grad_norm": 0.0,
      "learning_rate": 0.0001350747609137404,
      "loss": 1.0033,
      "step": 206
    },
    {
      "epoch": 0.8380566801619433,
      "grad_norm": 0.0,
      "learning_rate": 0.0001344466850284333,
      "loss": 1.0055,
      "step": 207
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.0,
      "learning_rate": 0.00013381706353330014,
      "loss": 0.972,
      "step": 208
    },
    {
      "epoch": 0.8461538461538461,
      "grad_norm": 0.0,
      "learning_rate": 0.0001331859246792211,
      "loss": 1.0063,
      "step": 209
    },
    {
      "epoch": 0.8502024291497976,
      "grad_norm": 0.0,
      "learning_rate": 0.0001325532967851596,
      "loss": 0.9878,
      "step": 210
    },
    {
      "epoch": 0.854251012145749,
      "grad_norm": 0.0,
      "learning_rate": 0.00013191920823689177,
      "loss": 0.9881,
      "step": 211
    },
    {
      "epoch": 0.8582995951417004,
      "grad_norm": 0.0,
      "learning_rate": 0.00013128368748573273,
      "loss": 0.9608,
      "step": 212
    },
    {
      "epoch": 0.8623481781376519,
      "grad_norm": 0.0,
      "learning_rate": 0.00013064676304726,
      "loss": 0.953,
      "step": 213
    },
    {
      "epoch": 0.8663967611336032,
      "grad_norm": 0.0,
      "learning_rate": 0.0001300084635000341,
      "loss": 0.9904,
      "step": 214
    },
    {
      "epoch": 0.8704453441295547,
      "grad_norm": 0.0,
      "learning_rate": 0.000129368817484316,
      "loss": 0.9877,
      "step": 215
    },
    {
      "epoch": 0.8744939271255061,
      "grad_norm": 0.0,
      "learning_rate": 0.0001287278537007824,
      "loss": 0.9723,
      "step": 216
    },
    {
      "epoch": 0.8785425101214575,
      "grad_norm": 0.0,
      "learning_rate": 0.00012808560090923758,
      "loss": 0.9724,
      "step": 217
    },
    {
      "epoch": 0.8825910931174089,
      "grad_norm": 0.0,
      "learning_rate": 0.00012744208792732324,
      "loss": 0.9404,
      "step": 218
    },
    {
      "epoch": 0.8866396761133604,
      "grad_norm": 0.0,
      "learning_rate": 0.00012679734362922528,
      "loss": 0.9661,
      "step": 219
    },
    {
      "epoch": 0.8906882591093117,
      "grad_norm": 0.0,
      "learning_rate": 0.00012615139694437835,
      "loss": 1.0048,
      "step": 220
    },
    {
      "epoch": 0.8947368421052632,
      "grad_norm": 0.0,
      "learning_rate": 0.00012550427685616765,
      "loss": 0.997,
      "step": 221
    },
    {
      "epoch": 0.8987854251012146,
      "grad_norm": 0.0,
      "learning_rate": 0.00012485601240062869,
      "loss": 1.0128,
      "step": 222
    },
    {
      "epoch": 0.902834008097166,
      "grad_norm": 0.0,
      "learning_rate": 0.00012420663266514417,
      "loss": 0.9684,
      "step": 223
    },
    {
      "epoch": 0.9068825910931174,
      "grad_norm": 0.0,
      "learning_rate": 0.0001235561667871391,
      "loss": 0.9546,
      "step": 224
    },
    {
      "epoch": 0.9109311740890689,
      "grad_norm": 0.0,
      "learning_rate": 0.0001229046439527732,
      "loss": 0.9762,
      "step": 225
    },
    {
      "epoch": 0.9149797570850202,
      "grad_norm": 0.0,
      "learning_rate": 0.00012225209339563145,
      "loss": 0.966,
      "step": 226
    },
    {
      "epoch": 0.9190283400809717,
      "grad_norm": 0.0,
      "learning_rate": 0.00012159854439541245,
      "loss": 0.9559,
      "step": 227
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 0.0,
      "learning_rate": 0.00012094402627661447,
      "loss": 0.9333,
      "step": 228
    },
    {
      "epoch": 0.9271255060728745,
      "grad_norm": 0.0,
      "learning_rate": 0.00012028856840721974,
      "loss": 0.9583,
      "step": 229
    },
    {
      "epoch": 0.9311740890688259,
      "grad_norm": 0.0,
      "learning_rate": 0.00011963220019737691,
      "loss": 1.0072,
      "step": 230
    },
    {
      "epoch": 0.9352226720647774,
      "grad_norm": 0.0,
      "learning_rate": 0.00011897495109808107,
      "loss": 0.9605,
      "step": 231
    },
    {
      "epoch": 0.9392712550607287,
      "grad_norm": 0.0,
      "learning_rate": 0.00011831685059985262,
      "loss": 0.9691,
      "step": 232
    },
    {
      "epoch": 0.9433198380566802,
      "grad_norm": 0.0,
      "learning_rate": 0.00011765792823141384,
      "loss": 0.9745,
      "step": 233
    },
    {
      "epoch": 0.9473684210526315,
      "grad_norm": 0.0,
      "learning_rate": 0.00011699821355836409,
      "loss": 0.9863,
      "step": 234
    },
    {
      "epoch": 0.951417004048583,
      "grad_norm": 0.0,
      "learning_rate": 0.00011633773618185302,
      "loss": 0.9542,
      "step": 235
    },
    {
      "epoch": 0.9554655870445344,
      "grad_norm": 0.0,
      "learning_rate": 0.00011567652573725262,
      "loss": 0.9872,
      "step": 236
    },
    {
      "epoch": 0.9595141700404858,
      "grad_norm": 0.0,
      "learning_rate": 0.00011501461189282733,
      "loss": 1.0047,
      "step": 237
    },
    {
      "epoch": 0.9635627530364372,
      "grad_norm": 0.0,
      "learning_rate": 0.00011435202434840287,
      "loss": 0.9462,
      "step": 238
    },
    {
      "epoch": 0.9676113360323887,
      "grad_norm": 0.0,
      "learning_rate": 0.0001136887928340336,
      "loss": 0.982,
      "step": 239
    },
    {
      "epoch": 0.97165991902834,
      "grad_norm": 0.0,
      "learning_rate": 0.00011302494710866857,
      "loss": 0.9465,
      "step": 240
    },
    {
      "epoch": 0.9757085020242915,
      "grad_norm": 0.0,
      "learning_rate": 0.00011236051695881633,
      "loss": 0.9978,
      "step": 241
    },
    {
      "epoch": 0.979757085020243,
      "grad_norm": 0.0,
      "learning_rate": 0.00011169553219720828,
      "loss": 0.944,
      "step": 242
    },
    {
      "epoch": 0.9838056680161943,
      "grad_norm": 0.0,
      "learning_rate": 0.00011103002266146096,
      "loss": 0.9887,
      "step": 243
    },
    {
      "epoch": 0.9878542510121457,
      "grad_norm": 0.0,
      "learning_rate": 0.0001103640182127375,
      "loss": 0.9735,
      "step": 244
    },
    {
      "epoch": 0.9919028340080972,
      "grad_norm": 0.0,
      "learning_rate": 0.00010969754873440743,
      "loss": 1.0015,
      "step": 245
    },
    {
      "epoch": 0.9959514170040485,
      "grad_norm": 0.0,
      "learning_rate": 0.00010903064413070612,
      "loss": 0.9771,
      "step": 246
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.0,
      "learning_rate": 0.00010836333432539272,
      "loss": 0.9546,
      "step": 247
    },
    {
      "epoch": 1.0040485829959513,
      "grad_norm": 0.0,
      "learning_rate": 0.00010769564926040769,
      "loss": 0.935,
      "step": 248
    },
    {
      "epoch": 1.008097165991903,
      "grad_norm": 0.0,
      "learning_rate": 0.0001070276188945293,
      "loss": 0.9799,
      "step": 249
    },
    {
      "epoch": 1.0121457489878543,
      "grad_norm": 0.0,
      "learning_rate": 0.00010635927320202928,
      "loss": 0.9736,
      "step": 250
    },
    {
      "epoch": 1.0161943319838056,
      "grad_norm": 0.0,
      "learning_rate": 0.00010569064217132791,
      "loss": 0.9839,
      "step": 251
    },
    {
      "epoch": 1.0202429149797572,
      "grad_norm": 0.0,
      "learning_rate": 0.00010502175580364857,
      "loss": 0.9579,
      "step": 252
    },
    {
      "epoch": 1.0242914979757085,
      "grad_norm": 0.0,
      "learning_rate": 0.00010435264411167148,
      "loss": 0.982,
      "step": 253
    },
    {
      "epoch": 1.0283400809716599,
      "grad_norm": 0.0,
      "learning_rate": 0.0001036833371181871,
      "loss": 0.9826,
      "step": 254
    },
    {
      "epoch": 1.0323886639676114,
      "grad_norm": 0.0,
      "learning_rate": 0.00010301386485474889,
      "loss": 0.9803,
      "step": 255
    },
    {
      "epoch": 1.0364372469635628,
      "grad_norm": 0.0,
      "learning_rate": 0.00010234425736032607,
      "loss": 0.9893,
      "step": 256
    },
    {
      "epoch": 1.040485829959514,
      "grad_norm": 0.0,
      "learning_rate": 0.00010167454467995549,
      "loss": 0.9193,
      "step": 257
    },
    {
      "epoch": 1.0445344129554657,
      "grad_norm": 0.0,
      "learning_rate": 0.00010100475686339379,
      "loss": 0.9718,
      "step": 258
    },
    {
      "epoch": 1.048582995951417,
      "grad_norm": 0.0,
      "learning_rate": 0.00010033492396376878,
      "loss": 0.9899,
      "step": 259
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 0.0,
      "learning_rate": 9.966507603623125e-05,
      "loss": 0.9395,
      "step": 260
    },
    {
      "epoch": 1.05668016194332,
      "grad_norm": 0.0,
      "learning_rate": 9.899524313660624e-05,
      "loss": 0.9386,
      "step": 261
    },
    {
      "epoch": 1.0607287449392713,
      "grad_norm": 0.0,
      "learning_rate": 9.832545532004454e-05,
      "loss": 0.967,
      "step": 262
    },
    {
      "epoch": 1.0647773279352226,
      "grad_norm": 0.0,
      "learning_rate": 9.765574263967396e-05,
      "loss": 0.9872,
      "step": 263
    },
    {
      "epoch": 1.0688259109311742,
      "grad_norm": 0.0,
      "learning_rate": 9.698613514525116e-05,
      "loss": 0.9563,
      "step": 264
    },
    {
      "epoch": 1.0728744939271255,
      "grad_norm": 0.0,
      "learning_rate": 9.631666288181293e-05,
      "loss": 0.9693,
      "step": 265
    },
    {
      "epoch": 1.0769230769230769,
      "grad_norm": 0.0,
      "learning_rate": 9.564735588832856e-05,
      "loss": 0.961,
      "step": 266
    },
    {
      "epoch": 1.0809716599190284,
      "grad_norm": 0.0,
      "learning_rate": 9.497824419635144e-05,
      "loss": 0.9801,
      "step": 267
    },
    {
      "epoch": 1.0850202429149798,
      "grad_norm": 0.0,
      "learning_rate": 9.430935782867212e-05,
      "loss": 0.9617,
      "step": 268
    },
    {
      "epoch": 1.0890688259109311,
      "grad_norm": 0.0,
      "learning_rate": 9.364072679797073e-05,
      "loss": 0.9403,
      "step": 269
    },
    {
      "epoch": 1.0931174089068827,
      "grad_norm": 0.0,
      "learning_rate": 9.297238110547074e-05,
      "loss": 0.9776,
      "step": 270
    },
    {
      "epoch": 1.097165991902834,
      "grad_norm": 0.0,
      "learning_rate": 9.230435073959232e-05,
      "loss": 0.9748,
      "step": 271
    },
    {
      "epoch": 1.1012145748987854,
      "grad_norm": 0.0,
      "learning_rate": 9.163666567460733e-05,
      "loss": 0.9535,
      "step": 272
    },
    {
      "epoch": 1.1052631578947367,
      "grad_norm": 0.0,
      "learning_rate": 9.096935586929392e-05,
      "loss": 0.9628,
      "step": 273
    },
    {
      "epoch": 1.1093117408906883,
      "grad_norm": 0.0,
      "learning_rate": 9.030245126559262e-05,
      "loss": 0.9162,
      "step": 274
    },
    {
      "epoch": 1.1133603238866396,
      "grad_norm": 0.0,
      "learning_rate": 8.963598178726254e-05,
      "loss": 0.9421,
      "step": 275
    },
    {
      "epoch": 1.117408906882591,
      "grad_norm": 0.0,
      "learning_rate": 8.896997733853903e-05,
      "loss": 0.9406,
      "step": 276
    },
    {
      "epoch": 1.1214574898785425,
      "grad_norm": 0.0,
      "learning_rate": 8.830446780279176e-05,
      "loss": 0.973,
      "step": 277
    },
    {
      "epoch": 1.125506072874494,
      "grad_norm": 0.0,
      "learning_rate": 8.763948304118368e-05,
      "loss": 0.9958,
      "step": 278
    },
    {
      "epoch": 1.1295546558704452,
      "grad_norm": 0.0,
      "learning_rate": 8.697505289133145e-05,
      "loss": 0.963,
      "step": 279
    },
    {
      "epoch": 1.1336032388663968,
      "grad_norm": 0.0,
      "learning_rate": 8.631120716596641e-05,
      "loss": 0.9419,
      "step": 280
    },
    {
      "epoch": 1.1376518218623481,
      "grad_norm": 0.0,
      "learning_rate": 8.564797565159714e-05,
      "loss": 0.9586,
      "step": 281
    },
    {
      "epoch": 1.1417004048582995,
      "grad_norm": 0.0,
      "learning_rate": 8.498538810717267e-05,
      "loss": 0.9748,
      "step": 282
    },
    {
      "epoch": 1.145748987854251,
      "grad_norm": 0.0,
      "learning_rate": 8.432347426274739e-05,
      "loss": 0.9682,
      "step": 283
    },
    {
      "epoch": 1.1497975708502024,
      "grad_norm": 0.0,
      "learning_rate": 8.366226381814697e-05,
      "loss": 0.9807,
      "step": 284
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 0.0,
      "learning_rate": 8.300178644163594e-05,
      "loss": 0.9625,
      "step": 285
    },
    {
      "epoch": 1.1578947368421053,
      "grad_norm": 0.0,
      "learning_rate": 8.234207176858614e-05,
      "loss": 0.9902,
      "step": 286
    },
    {
      "epoch": 1.1619433198380567,
      "grad_norm": 0.0,
      "learning_rate": 8.16831494001474e-05,
      "loss": 0.9476,
      "step": 287
    },
    {
      "epoch": 1.165991902834008,
      "grad_norm": 0.0,
      "learning_rate": 8.102504890191892e-05,
      "loss": 0.9156,
      "step": 288
    },
    {
      "epoch": 1.1700404858299596,
      "grad_norm": 0.0,
      "learning_rate": 8.036779980262311e-05,
      "loss": 0.9645,
      "step": 289
    },
    {
      "epoch": 1.174089068825911,
      "grad_norm": 0.0,
      "learning_rate": 7.971143159278026e-05,
      "loss": 0.9525,
      "step": 290
    },
    {
      "epoch": 1.1781376518218623,
      "grad_norm": 0.0,
      "learning_rate": 7.905597372338558e-05,
      "loss": 0.9573,
      "step": 291
    },
    {
      "epoch": 1.1821862348178138,
      "grad_norm": 0.0,
      "learning_rate": 7.840145560458756e-05,
      "loss": 0.9338,
      "step": 292
    },
    {
      "epoch": 1.1862348178137652,
      "grad_norm": 0.0,
      "learning_rate": 7.774790660436858e-05,
      "loss": 0.9812,
      "step": 293
    },
    {
      "epoch": 1.1902834008097165,
      "grad_norm": 0.0,
      "learning_rate": 7.709535604722684e-05,
      "loss": 0.9555,
      "step": 294
    },
    {
      "epoch": 1.194331983805668,
      "grad_norm": 0.0,
      "learning_rate": 7.644383321286094e-05,
      "loss": 0.9756,
      "step": 295
    },
    {
      "epoch": 1.1983805668016194,
      "grad_norm": 0.0,
      "learning_rate": 7.579336733485584e-05,
      "loss": 0.9495,
      "step": 296
    },
    {
      "epoch": 1.2024291497975708,
      "grad_norm": 0.0,
      "learning_rate": 7.514398759937135e-05,
      "loss": 0.9779,
      "step": 297
    },
    {
      "epoch": 1.2064777327935223,
      "grad_norm": 0.0,
      "learning_rate": 7.449572314383237e-05,
      "loss": 0.9518,
      "step": 298
    },
    {
      "epoch": 1.2105263157894737,
      "grad_norm": 0.0,
      "learning_rate": 7.384860305562172e-05,
      "loss": 0.9499,
      "step": 299
    },
    {
      "epoch": 1.214574898785425,
      "grad_norm": 0.0,
      "learning_rate": 7.320265637077473e-05,
      "loss": 0.965,
      "step": 300
    },
    {
      "epoch": 1.2186234817813766,
      "grad_norm": 0.0,
      "learning_rate": 7.255791207267679e-05,
      "loss": 0.9575,
      "step": 301
    },
    {
      "epoch": 1.222672064777328,
      "grad_norm": 0.0,
      "learning_rate": 7.191439909076243e-05,
      "loss": 0.9783,
      "step": 302
    },
    {
      "epoch": 1.2267206477732793,
      "grad_norm": 0.0,
      "learning_rate": 7.127214629921765e-05,
      "loss": 0.9665,
      "step": 303
    },
    {
      "epoch": 1.2307692307692308,
      "grad_norm": 0.0,
      "learning_rate": 7.0631182515684e-05,
      "loss": 0.9784,
      "step": 304
    },
    {
      "epoch": 1.2348178137651822,
      "grad_norm": 0.0,
      "learning_rate": 6.999153649996595e-05,
      "loss": 0.9475,
      "step": 305
    },
    {
      "epoch": 1.2388663967611335,
      "grad_norm": 0.0,
      "learning_rate": 6.935323695274002e-05,
      "loss": 0.9256,
      "step": 306
    },
    {
      "epoch": 1.242914979757085,
      "grad_norm": 0.0,
      "learning_rate": 6.871631251426728e-05,
      "loss": 0.9343,
      "step": 307
    },
    {
      "epoch": 1.2469635627530364,
      "grad_norm": 0.0,
      "learning_rate": 6.808079176310827e-05,
      "loss": 0.9739,
      "step": 308
    },
    {
      "epoch": 1.2510121457489878,
      "grad_norm": 0.0,
      "learning_rate": 6.744670321484043e-05,
      "loss": 0.9773,
      "step": 309
    },
    {
      "epoch": 1.2550607287449393,
      "grad_norm": 0.0,
      "learning_rate": 6.681407532077895e-05,
      "loss": 0.9703,
      "step": 310
    },
    {
      "epoch": 1.2591093117408907,
      "grad_norm": 0.0,
      "learning_rate": 6.618293646669986e-05,
      "loss": 0.9476,
      "step": 311
    },
    {
      "epoch": 1.263157894736842,
      "grad_norm": 0.0,
      "learning_rate": 6.555331497156672e-05,
      "loss": 0.9765,
      "step": 312
    },
    {
      "epoch": 1.2672064777327936,
      "grad_norm": 0.0,
      "learning_rate": 6.492523908625959e-05,
      "loss": 1.019,
      "step": 313
    },
    {
      "epoch": 1.271255060728745,
      "grad_norm": 0.0,
      "learning_rate": 6.42987369923077e-05,
      "loss": 1.0173,
      "step": 314
    },
    {
      "epoch": 1.2753036437246963,
      "grad_norm": 0.0,
      "learning_rate": 6.367383680062478e-05,
      "loss": 1.0097,
      "step": 315
    },
    {
      "epoch": 1.2793522267206479,
      "grad_norm": 0.0,
      "learning_rate": 6.30505665502479e-05,
      "loss": 0.9893,
      "step": 316
    },
    {
      "epoch": 1.2834008097165992,
      "grad_norm": 0.0,
      "learning_rate": 6.242895420707917e-05,
      "loss": 0.9556,
      "step": 317
    },
    {
      "epoch": 1.2874493927125505,
      "grad_norm": 0.0,
      "learning_rate": 6.180902766263113e-05,
      "loss": 0.9325,
      "step": 318
    },
    {
      "epoch": 1.291497975708502,
      "grad_norm": 0.0,
      "learning_rate": 6.119081473277501e-05,
      "loss": 0.9661,
      "step": 319
    },
    {
      "epoch": 1.2955465587044535,
      "grad_norm": 0.0,
      "learning_rate": 6.057434315649304e-05,
      "loss": 0.9348,
      "step": 320
    },
    {
      "epoch": 1.2995951417004048,
      "grad_norm": 0.0,
      "learning_rate": 5.99596405946333e-05,
      "loss": 0.9276,
      "step": 321
    },
    {
      "epoch": 1.3036437246963564,
      "grad_norm": 0.0,
      "learning_rate": 5.9346734628669065e-05,
      "loss": 0.9988,
      "step": 322
    },
    {
      "epoch": 1.3076923076923077,
      "grad_norm": 0.0,
      "learning_rate": 5.873565275946088e-05,
      "loss": 0.9574,
      "step": 323
    },
    {
      "epoch": 1.311740890688259,
      "grad_norm": 0.0,
      "learning_rate": 5.8126422406022885e-05,
      "loss": 0.9795,
      "step": 324
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.0,
      "learning_rate": 5.7519070904292247e-05,
      "loss": 0.9825,
      "step": 325
    },
    {
      "epoch": 1.319838056680162,
      "grad_norm": 0.0,
      "learning_rate": 5.691362550590297e-05,
      "loss": 0.9799,
      "step": 326
    },
    {
      "epoch": 1.3238866396761133,
      "grad_norm": 0.0,
      "learning_rate": 5.631011337696271e-05,
      "loss": 0.9542,
      "step": 327
    },
    {
      "epoch": 1.3279352226720649,
      "grad_norm": 0.0,
      "learning_rate": 5.570856159683418e-05,
      "loss": 0.9807,
      "step": 328
    },
    {
      "epoch": 1.3319838056680162,
      "grad_norm": 0.0,
      "learning_rate": 5.510899715691984e-05,
      "loss": 0.984,
      "step": 329
    },
    {
      "epoch": 1.3360323886639676,
      "grad_norm": 0.0,
      "learning_rate": 5.451144695945116e-05,
      "loss": 0.9385,
      "step": 330
    },
    {
      "epoch": 1.3400809716599191,
      "grad_norm": 0.0,
      "learning_rate": 5.3915937816281095e-05,
      "loss": 0.9863,
      "step": 331
    },
    {
      "epoch": 1.3441295546558705,
      "grad_norm": 0.0,
      "learning_rate": 5.3322496447681414e-05,
      "loss": 0.957,
      "step": 332
    },
    {
      "epoch": 1.3481781376518218,
      "grad_norm": 0.0,
      "learning_rate": 5.273114948114346e-05,
      "loss": 0.9636,
      "step": 333
    },
    {
      "epoch": 1.3522267206477734,
      "grad_norm": 0.0,
      "learning_rate": 5.214192345018374e-05,
      "loss": 0.9849,
      "step": 334
    },
    {
      "epoch": 1.3562753036437247,
      "grad_norm": 0.0,
      "learning_rate": 5.1554844793153e-05,
      "loss": 0.9627,
      "step": 335
    },
    {
      "epoch": 1.360323886639676,
      "grad_norm": 0.0,
      "learning_rate": 5.096993985205023e-05,
      "loss": 0.9638,
      "step": 336
    },
    {
      "epoch": 1.3643724696356276,
      "grad_norm": 0.0,
      "learning_rate": 5.0387234871340486e-05,
      "loss": 0.9502,
      "step": 337
    },
    {
      "epoch": 1.368421052631579,
      "grad_norm": 0.0,
      "learning_rate": 4.980675599677757e-05,
      "loss": 0.9698,
      "step": 338
    },
    {
      "epoch": 1.3724696356275303,
      "grad_norm": 0.0,
      "learning_rate": 4.9228529274230695e-05,
      "loss": 0.9829,
      "step": 339
    },
    {
      "epoch": 1.376518218623482,
      "grad_norm": 0.0,
      "learning_rate": 4.865258064851579e-05,
      "loss": 0.972,
      "step": 340
    },
    {
      "epoch": 1.3805668016194332,
      "grad_norm": 0.0,
      "learning_rate": 4.807893596223152e-05,
      "loss": 0.9377,
      "step": 341
    },
    {
      "epoch": 1.3846153846153846,
      "grad_norm": 0.0,
      "learning_rate": 4.75076209545996e-05,
      "loss": 0.9654,
      "step": 342
    },
    {
      "epoch": 1.3886639676113361,
      "grad_norm": 0.0,
      "learning_rate": 4.693866126030995e-05,
      "loss": 0.947,
      "step": 343
    },
    {
      "epoch": 1.3927125506072875,
      "grad_norm": 0.0,
      "learning_rate": 4.637208240837042e-05,
      "loss": 0.9983,
      "step": 344
    },
    {
      "epoch": 1.3967611336032388,
      "grad_norm": 0.0,
      "learning_rate": 4.5807909820961494e-05,
      "loss": 0.9625,
      "step": 345
    },
    {
      "epoch": 1.4008097165991904,
      "grad_norm": 0.0,
      "learning_rate": 4.5246168812295286e-05,
      "loss": 0.9647,
      "step": 346
    },
    {
      "epoch": 1.4048582995951417,
      "grad_norm": 0.0,
      "learning_rate": 4.468688458748006e-05,
      "loss": 0.9718,
      "step": 347
    },
    {
      "epoch": 1.408906882591093,
      "grad_norm": 0.0,
      "learning_rate": 4.413008224138897e-05,
      "loss": 0.9967,
      "step": 348
    },
    {
      "epoch": 1.4129554655870447,
      "grad_norm": 0.0,
      "learning_rate": 4.357578675753432e-05,
      "loss": 0.9366,
      "step": 349
    },
    {
      "epoch": 1.417004048582996,
      "grad_norm": 0.0,
      "learning_rate": 4.302402300694636e-05,
      "loss": 0.9667,
      "step": 350
    },
    {
      "epoch": 1.4210526315789473,
      "grad_norm": 0.0,
      "learning_rate": 4.247481574705744e-05,
      "loss": 0.9362,
      "step": 351
    },
    {
      "epoch": 1.425101214574899,
      "grad_norm": 0.0,
      "learning_rate": 4.1928189620591116e-05,
      "loss": 0.9509,
      "step": 352
    },
    {
      "epoch": 1.4291497975708503,
      "grad_norm": 0.0,
      "learning_rate": 4.138416915445655e-05,
      "loss": 0.9744,
      "step": 353
    },
    {
      "epoch": 1.4331983805668016,
      "grad_norm": 0.0,
      "learning_rate": 4.084277875864776e-05,
      "loss": 0.9658,
      "step": 354
    },
    {
      "epoch": 1.4372469635627532,
      "grad_norm": 0.0,
      "learning_rate": 4.030404272514864e-05,
      "loss": 0.9091,
      "step": 355
    },
    {
      "epoch": 1.4412955465587045,
      "grad_norm": 0.0,
      "learning_rate": 3.9767985226842696e-05,
      "loss": 0.9631,
      "step": 356
    },
    {
      "epoch": 1.4453441295546559,
      "grad_norm": 0.0,
      "learning_rate": 3.923463031642872e-05,
      "loss": 0.9766,
      "step": 357
    },
    {
      "epoch": 1.4493927125506074,
      "grad_norm": 0.0,
      "learning_rate": 3.870400192534128e-05,
      "loss": 0.9289,
      "step": 358
    },
    {
      "epoch": 1.4534412955465588,
      "grad_norm": 0.0,
      "learning_rate": 3.81761238626771e-05,
      "loss": 0.9665,
      "step": 359
    },
    {
      "epoch": 1.45748987854251,
      "grad_norm": 0.0,
      "learning_rate": 3.7651019814126654e-05,
      "loss": 0.9473,
      "step": 360
    },
    {
      "epoch": 1.4615384615384617,
      "grad_norm": 0.0,
      "learning_rate": 3.7128713340911535e-05,
      "loss": 1.001,
      "step": 361
    },
    {
      "epoch": 1.465587044534413,
      "grad_norm": 0.0,
      "learning_rate": 3.660922787872706e-05,
      "loss": 0.9193,
      "step": 362
    },
    {
      "epoch": 1.4696356275303644,
      "grad_norm": 0.0,
      "learning_rate": 3.609258673669097e-05,
      "loss": 0.9639,
      "step": 363
    },
    {
      "epoch": 1.4736842105263157,
      "grad_norm": 0.0,
      "learning_rate": 3.557881309629729e-05,
      "loss": 0.9651,
      "step": 364
    },
    {
      "epoch": 1.4777327935222673,
      "grad_norm": 0.0,
      "learning_rate": 3.5067930010376484e-05,
      "loss": 0.974,
      "step": 365
    },
    {
      "epoch": 1.4817813765182186,
      "grad_norm": 0.0,
      "learning_rate": 3.455996040206076e-05,
      "loss": 0.9718,
      "step": 366
    },
    {
      "epoch": 1.48582995951417,
      "grad_norm": 0.0,
      "learning_rate": 3.4054927063755796e-05,
      "loss": 0.9408,
      "step": 367
    },
    {
      "epoch": 1.4898785425101215,
      "grad_norm": 0.0,
      "learning_rate": 3.355285265611784e-05,
      "loss": 0.9817,
      "step": 368
    },
    {
      "epoch": 1.4939271255060729,
      "grad_norm": 0.0,
      "learning_rate": 3.305375970703711e-05,
      "loss": 0.9591,
      "step": 369
    },
    {
      "epoch": 1.4979757085020242,
      "grad_norm": 0.0,
      "learning_rate": 3.2557670610626925e-05,
      "loss": 0.9882,
      "step": 370
    },
    {
      "epoch": 1.5020242914979756,
      "grad_norm": 0.0,
      "learning_rate": 3.206460762621873e-05,
      "loss": 0.9703,
      "step": 371
    },
    {
      "epoch": 1.5060728744939271,
      "grad_norm": 0.0,
      "learning_rate": 3.157459287736362e-05,
      "loss": 0.9722,
      "step": 372
    },
    {
      "epoch": 1.5101214574898787,
      "grad_norm": 0.0,
      "learning_rate": 3.108764835083938e-05,
      "loss": 0.9966,
      "step": 373
    },
    {
      "epoch": 1.5141700404858298,
      "grad_norm": 0.0,
      "learning_rate": 3.0603795895664124e-05,
      "loss": 1.0014,
      "step": 374
    },
    {
      "epoch": 1.5182186234817814,
      "grad_norm": 0.0,
      "learning_rate": 3.0123057222115836e-05,
      "loss": 0.9824,
      "step": 375
    },
    {
      "epoch": 1.522267206477733,
      "grad_norm": 0.0,
      "learning_rate": 2.964545390075841e-05,
      "loss": 0.9788,
      "step": 376
    },
    {
      "epoch": 1.526315789473684,
      "grad_norm": 0.0,
      "learning_rate": 2.9171007361473514e-05,
      "loss": 0.9224,
      "step": 377
    },
    {
      "epoch": 1.5303643724696356,
      "grad_norm": 0.0,
      "learning_rate": 2.8699738892499328e-05,
      "loss": 0.9694,
      "step": 378
    },
    {
      "epoch": 1.5344129554655872,
      "grad_norm": 0.0,
      "learning_rate": 2.8231669639475067e-05,
      "loss": 0.9831,
      "step": 379
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.0,
      "learning_rate": 2.776682060449247e-05,
      "loss": 0.9843,
      "step": 380
    },
    {
      "epoch": 1.54251012145749,
      "grad_norm": 0.0,
      "learning_rate": 2.7305212645153212e-05,
      "loss": 0.981,
      "step": 381
    },
    {
      "epoch": 1.5465587044534415,
      "grad_norm": 0.0,
      "learning_rate": 2.6846866473633125e-05,
      "loss": 0.9357,
      "step": 382
    },
    {
      "epoch": 1.5506072874493926,
      "grad_norm": 0.0,
      "learning_rate": 2.6391802655752853e-05,
      "loss": 0.9541,
      "step": 383
    },
    {
      "epoch": 1.5546558704453441,
      "grad_norm": 0.0,
      "learning_rate": 2.594004161005511e-05,
      "loss": 0.9304,
      "step": 384
    },
    {
      "epoch": 1.5587044534412957,
      "grad_norm": 0.0,
      "learning_rate": 2.549160360688838e-05,
      "loss": 0.989,
      "step": 385
    },
    {
      "epoch": 1.5627530364372468,
      "grad_norm": 0.0,
      "learning_rate": 2.50465087674976e-05,
      "loss": 0.9566,
      "step": 386
    },
    {
      "epoch": 1.5668016194331984,
      "grad_norm": 0.0,
      "learning_rate": 2.4604777063121033e-05,
      "loss": 0.921,
      "step": 387
    },
    {
      "epoch": 1.5708502024291497,
      "grad_norm": 0.0,
      "learning_rate": 2.4166428314094514e-05,
      "loss": 0.974,
      "step": 388
    },
    {
      "epoch": 1.574898785425101,
      "grad_norm": 0.0,
      "learning_rate": 2.3731482188961818e-05,
      "loss": 0.9205,
      "step": 389
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 0.0,
      "learning_rate": 2.32999582035923e-05,
      "loss": 0.9843,
      "step": 390
    },
    {
      "epoch": 1.582995951417004,
      "grad_norm": 0.0,
      "learning_rate": 2.287187572030516e-05,
      "loss": 0.9602,
      "step": 391
    },
    {
      "epoch": 1.5870445344129553,
      "grad_norm": 0.0,
      "learning_rate": 2.244725394700079e-05,
      "loss": 0.9536,
      "step": 392
    },
    {
      "epoch": 1.591093117408907,
      "grad_norm": 0.0,
      "learning_rate": 2.202611193629869e-05,
      "loss": 0.9845,
      "step": 393
    },
    {
      "epoch": 1.5951417004048583,
      "grad_norm": 0.0,
      "learning_rate": 2.160846858468285e-05,
      "loss": 0.9763,
      "step": 394
    },
    {
      "epoch": 1.5991902834008096,
      "grad_norm": 0.0,
      "learning_rate": 2.1194342631653607e-05,
      "loss": 0.953,
      "step": 395
    },
    {
      "epoch": 1.6032388663967612,
      "grad_norm": 0.0,
      "learning_rate": 2.0783752658887066e-05,
      "loss": 0.9446,
      "step": 396
    },
    {
      "epoch": 1.6072874493927125,
      "grad_norm": 0.0,
      "learning_rate": 2.0376717089401164e-05,
      "loss": 0.9577,
      "step": 397
    },
    {
      "epoch": 1.6113360323886639,
      "grad_norm": 0.0,
      "learning_rate": 1.9973254186729086e-05,
      "loss": 0.9772,
      "step": 398
    },
    {
      "epoch": 1.6153846153846154,
      "grad_norm": 0.0,
      "learning_rate": 1.9573382054099786e-05,
      "loss": 0.9886,
      "step": 399
    },
    {
      "epoch": 1.6194331983805668,
      "grad_norm": 0.0,
      "learning_rate": 1.9177118633625814e-05,
      "loss": 0.9702,
      "step": 400
    },
    {
      "epoch": 1.623481781376518,
      "grad_norm": 0.0,
      "learning_rate": 1.8784481705498015e-05,
      "loss": 0.9557,
      "step": 401
    },
    {
      "epoch": 1.6275303643724697,
      "grad_norm": 0.0,
      "learning_rate": 1.8395488887188005e-05,
      "loss": 0.9324,
      "step": 402
    },
    {
      "epoch": 1.631578947368421,
      "grad_norm": 0.0,
      "learning_rate": 1.8010157632657543e-05,
      "loss": 0.9749,
      "step": 403
    },
    {
      "epoch": 1.6356275303643724,
      "grad_norm": 0.0,
      "learning_rate": 1.762850523157532e-05,
      "loss": 0.95,
      "step": 404
    },
    {
      "epoch": 1.639676113360324,
      "grad_norm": 0.0,
      "learning_rate": 1.7250548808541322e-05,
      "loss": 0.9437,
      "step": 405
    },
    {
      "epoch": 1.6437246963562753,
      "grad_norm": 0.0,
      "learning_rate": 1.687630532231833e-05,
      "loss": 1.0033,
      "step": 406
    },
    {
      "epoch": 1.6477732793522266,
      "grad_norm": 0.0,
      "learning_rate": 1.6505791565071138e-05,
      "loss": 0.9441,
      "step": 407
    },
    {
      "epoch": 1.6518218623481782,
      "grad_norm": 0.0,
      "learning_rate": 1.613902416161288e-05,
      "loss": 0.9808,
      "step": 408
    },
    {
      "epoch": 1.6558704453441295,
      "grad_norm": 0.0,
      "learning_rate": 1.5776019568659338e-05,
      "loss": 0.9782,
      "step": 409
    },
    {
      "epoch": 1.6599190283400809,
      "grad_norm": 0.0,
      "learning_rate": 1.5416794074090258e-05,
      "loss": 0.9791,
      "step": 410
    },
    {
      "epoch": 1.6639676113360324,
      "grad_norm": 0.0,
      "learning_rate": 1.5061363796218785e-05,
      "loss": 0.9909,
      "step": 411
    },
    {
      "epoch": 1.6680161943319838,
      "grad_norm": 0.0,
      "learning_rate": 1.4709744683068039e-05,
      "loss": 0.9484,
      "step": 412
    },
    {
      "epoch": 1.6720647773279351,
      "grad_norm": 0.0,
      "learning_rate": 1.4361952511655618e-05,
      "loss": 0.9288,
      "step": 413
    },
    {
      "epoch": 1.6761133603238867,
      "grad_norm": 0.0,
      "learning_rate": 1.4018002887285687e-05,
      "loss": 0.977,
      "step": 414
    },
    {
      "epoch": 1.680161943319838,
      "grad_norm": 0.0,
      "learning_rate": 1.3677911242848806e-05,
      "loss": 0.9548,
      "step": 415
    },
    {
      "epoch": 1.6842105263157894,
      "grad_norm": 0.0,
      "learning_rate": 1.334169283812936e-05,
      "loss": 0.9934,
      "step": 416
    },
    {
      "epoch": 1.688259109311741,
      "grad_norm": 0.0,
      "learning_rate": 1.300936275912098e-05,
      "loss": 0.9903,
      "step": 417
    },
    {
      "epoch": 1.6923076923076923,
      "grad_norm": 0.0,
      "learning_rate": 1.2680935917349523e-05,
      "loss": 0.9378,
      "step": 418
    },
    {
      "epoch": 1.6963562753036436,
      "grad_norm": 0.0,
      "learning_rate": 1.2356427049204122e-05,
      "loss": 0.994,
      "step": 419
    },
    {
      "epoch": 1.7004048582995952,
      "grad_norm": 0.0,
      "learning_rate": 1.2035850715275865e-05,
      "loss": 0.9664,
      "step": 420
    },
    {
      "epoch": 1.7044534412955465,
      "grad_norm": 0.0,
      "learning_rate": 1.1719221299704497e-05,
      "loss": 0.9318,
      "step": 421
    },
    {
      "epoch": 1.708502024291498,
      "grad_norm": 0.0,
      "learning_rate": 1.1406553009533027e-05,
      "loss": 0.9603,
      "step": 422
    },
    {
      "epoch": 1.7125506072874495,
      "grad_norm": 0.0,
      "learning_rate": 1.1097859874070294e-05,
      "loss": 0.9195,
      "step": 423
    },
    {
      "epoch": 1.7165991902834008,
      "grad_norm": 0.0,
      "learning_rate": 1.0793155744261351e-05,
      "loss": 0.9455,
      "step": 424
    },
    {
      "epoch": 1.7206477732793521,
      "grad_norm": 0.0,
      "learning_rate": 1.0492454292066178e-05,
      "loss": 0.9387,
      "step": 425
    },
    {
      "epoch": 1.7246963562753037,
      "grad_norm": 0.0,
      "learning_rate": 1.019576900984599e-05,
      "loss": 0.9287,
      "step": 426
    },
    {
      "epoch": 1.728744939271255,
      "grad_norm": 0.0,
      "learning_rate": 9.903113209758096e-06,
      "loss": 0.9274,
      "step": 427
    },
    {
      "epoch": 1.7327935222672064,
      "grad_norm": 0.0,
      "learning_rate": 9.614500023158336e-06,
      "loss": 0.957,
      "step": 428
    },
    {
      "epoch": 1.736842105263158,
      "grad_norm": 0.0,
      "learning_rate": 9.32994240001206e-06,
      "loss": 0.9741,
      "step": 429
    },
    {
      "epoch": 1.7408906882591093,
      "grad_norm": 0.0,
      "learning_rate": 9.049453108312966e-06,
      "loss": 0.9638,
      "step": 430
    },
    {
      "epoch": 1.7449392712550607,
      "grad_norm": 0.0,
      "learning_rate": 8.773044733510338e-06,
      "loss": 0.9711,
      "step": 431
    },
    {
      "epoch": 1.7489878542510122,
      "grad_norm": 0.0,
      "learning_rate": 8.50072967794413e-06,
      "loss": 0.961,
      "step": 432
    },
    {
      "epoch": 1.7530364372469636,
      "grad_norm": 0.0,
      "learning_rate": 8.232520160288704e-06,
      "loss": 0.9734,
      "step": 433
    },
    {
      "epoch": 1.757085020242915,
      "grad_norm": 0.0,
      "learning_rate": 7.96842821500442e-06,
      "loss": 0.9437,
      "step": 434
    },
    {
      "epoch": 1.7611336032388665,
      "grad_norm": 0.0,
      "learning_rate": 7.708465691797717e-06,
      "loss": 0.9305,
      "step": 435
    },
    {
      "epoch": 1.7651821862348178,
      "grad_norm": 0.0,
      "learning_rate": 7.452644255089425e-06,
      "loss": 0.9363,
      "step": 436
    },
    {
      "epoch": 1.7692307692307692,
      "grad_norm": 0.0,
      "learning_rate": 7.20097538349136e-06,
      "loss": 0.9579,
      "step": 437
    },
    {
      "epoch": 1.7732793522267207,
      "grad_norm": 0.0,
      "learning_rate": 6.953470369291348e-06,
      "loss": 0.9426,
      "step": 438
    },
    {
      "epoch": 1.777327935222672,
      "grad_norm": 0.0,
      "learning_rate": 6.710140317946423e-06,
      "loss": 0.9935,
      "step": 439
    },
    {
      "epoch": 1.7813765182186234,
      "grad_norm": 0.0,
      "learning_rate": 6.470996147584685e-06,
      "loss": 0.9767,
      "step": 440
    },
    {
      "epoch": 1.785425101214575,
      "grad_norm": 0.0,
      "learning_rate": 6.236048588515242e-06,
      "loss": 0.9366,
      "step": 441
    },
    {
      "epoch": 1.7894736842105263,
      "grad_norm": 0.0,
      "learning_rate": 6.0053081827469045e-06,
      "loss": 0.9881,
      "step": 442
    },
    {
      "epoch": 1.7935222672064777,
      "grad_norm": 0.0,
      "learning_rate": 5.778785283515053e-06,
      "loss": 0.9478,
      "step": 443
    },
    {
      "epoch": 1.7975708502024292,
      "grad_norm": 0.0,
      "learning_rate": 5.556490054817132e-06,
      "loss": 0.9514,
      "step": 444
    },
    {
      "epoch": 1.8016194331983806,
      "grad_norm": 0.0,
      "learning_rate": 5.338432470956589e-06,
      "loss": 0.9651,
      "step": 445
    },
    {
      "epoch": 1.805668016194332,
      "grad_norm": 0.0,
      "learning_rate": 5.1246223160953845e-06,
      "loss": 0.9288,
      "step": 446
    },
    {
      "epoch": 1.8097165991902835,
      "grad_norm": 0.0,
      "learning_rate": 4.91506918381488e-06,
      "loss": 0.9232,
      "step": 447
    },
    {
      "epoch": 1.8137651821862348,
      "grad_norm": 0.0,
      "learning_rate": 4.7097824766854756e-06,
      "loss": 0.949,
      "step": 448
    },
    {
      "epoch": 1.8178137651821862,
      "grad_norm": 0.0,
      "learning_rate": 4.508771405844636e-06,
      "loss": 0.9276,
      "step": 449
    },
    {
      "epoch": 1.8218623481781377,
      "grad_norm": 0.0,
      "learning_rate": 4.312044990583675e-06,
      "loss": 0.9634,
      "step": 450
    },
    {
      "epoch": 1.825910931174089,
      "grad_norm": 0.0,
      "learning_rate": 4.119612057942978e-06,
      "loss": 0.9266,
      "step": 451
    },
    {
      "epoch": 1.8299595141700404,
      "grad_norm": 0.0,
      "learning_rate": 3.931481242315993e-06,
      "loss": 0.9582,
      "step": 452
    },
    {
      "epoch": 1.834008097165992,
      "grad_norm": 0.0,
      "learning_rate": 3.747660985061785e-06,
      "loss": 0.9732,
      "step": 453
    },
    {
      "epoch": 1.8380566801619433,
      "grad_norm": 0.0,
      "learning_rate": 3.568159534126314e-06,
      "loss": 0.9855,
      "step": 454
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 0.0,
      "learning_rate": 3.3929849436722728e-06,
      "loss": 0.9803,
      "step": 455
    },
    {
      "epoch": 1.8461538461538463,
      "grad_norm": 0.0,
      "learning_rate": 3.2221450737178083e-06,
      "loss": 0.9656,
      "step": 456
    },
    {
      "epoch": 1.8502024291497976,
      "grad_norm": 0.0,
      "learning_rate": 3.0556475897837166e-06,
      "loss": 0.9432,
      "step": 457
    },
    {
      "epoch": 1.854251012145749,
      "grad_norm": 0.0,
      "learning_rate": 2.8934999625496282e-06,
      "loss": 0.9857,
      "step": 458
    },
    {
      "epoch": 1.8582995951417005,
      "grad_norm": 0.0,
      "learning_rate": 2.735709467518699e-06,
      "loss": 0.9566,
      "step": 459
    },
    {
      "epoch": 1.8623481781376519,
      "grad_norm": 0.0,
      "learning_rate": 2.5822831846912033e-06,
      "loss": 0.9533,
      "step": 460
    },
    {
      "epoch": 1.8663967611336032,
      "grad_norm": 0.0,
      "learning_rate": 2.4332279982468453e-06,
      "loss": 0.9373,
      "step": 461
    },
    {
      "epoch": 1.8704453441295548,
      "grad_norm": 0.0,
      "learning_rate": 2.2885505962359054e-06,
      "loss": 0.9489,
      "step": 462
    },
    {
      "epoch": 1.874493927125506,
      "grad_norm": 0.0,
      "learning_rate": 2.1482574702790803e-06,
      "loss": 0.9526,
      "step": 463
    },
    {
      "epoch": 1.8785425101214575,
      "grad_norm": 0.0,
      "learning_rate": 2.0123549152762823e-06,
      "loss": 0.9642,
      "step": 464
    },
    {
      "epoch": 1.882591093117409,
      "grad_norm": 0.0,
      "learning_rate": 1.8808490291241432e-06,
      "loss": 0.9639,
      "step": 465
    },
    {
      "epoch": 1.8866396761133604,
      "grad_norm": 0.0,
      "learning_rate": 1.7537457124423895e-06,
      "loss": 0.9577,
      "step": 466
    },
    {
      "epoch": 1.8906882591093117,
      "grad_norm": 0.0,
      "learning_rate": 1.631050668309131e-06,
      "loss": 0.9664,
      "step": 467
    },
    {
      "epoch": 1.8947368421052633,
      "grad_norm": 0.0,
      "learning_rate": 1.5127694020049432e-06,
      "loss": 0.9768,
      "step": 468
    },
    {
      "epoch": 1.8987854251012146,
      "grad_norm": 0.0,
      "learning_rate": 1.3989072207658328e-06,
      "loss": 0.9251,
      "step": 469
    },
    {
      "epoch": 1.902834008097166,
      "grad_norm": 0.0,
      "learning_rate": 1.2894692335451375e-06,
      "loss": 0.9535,
      "step": 470
    },
    {
      "epoch": 1.9068825910931175,
      "grad_norm": 0.0,
      "learning_rate": 1.1844603507842668e-06,
      "loss": 0.9544,
      "step": 471
    },
    {
      "epoch": 1.9109311740890689,
      "grad_norm": 0.0,
      "learning_rate": 1.083885284192354e-06,
      "loss": 0.9298,
      "step": 472
    },
    {
      "epoch": 1.9149797570850202,
      "grad_norm": 0.0,
      "learning_rate": 9.877485465349058e-07,
      "loss": 0.9646,
      "step": 473
    },
    {
      "epoch": 1.9190283400809718,
      "grad_norm": 0.0,
      "learning_rate": 8.960544514312275e-07,
      "loss": 0.9435,
      "step": 474
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.0,
      "learning_rate": 8.088071131609587e-07,
      "loss": 0.9375,
      "step": 475
    },
    {
      "epoch": 1.9271255060728745,
      "grad_norm": 0.0,
      "learning_rate": 7.26010446479397e-07,
      "loss": 0.925,
      "step": 476
    },
    {
      "epoch": 1.931174089068826,
      "grad_norm": 0.0,
      "learning_rate": 6.476681664419171e-07,
      "loss": 0.9919,
      "step": 477
    },
    {
      "epoch": 1.9352226720647774,
      "grad_norm": 0.0,
      "learning_rate": 5.737837882371922e-07,
      "loss": 0.9715,
      "step": 478
    },
    {
      "epoch": 1.9392712550607287,
      "grad_norm": 0.0,
      "learning_rate": 5.043606270295654e-07,
      "loss": 0.9596,
      "step": 479
    },
    {
      "epoch": 1.9433198380566803,
      "grad_norm": 0.0,
      "learning_rate": 4.3940179781019055e-07,
      "loss": 1.0135,
      "step": 480
    },
    {
      "epoch": 1.9473684210526314,
      "grad_norm": 0.0,
      "learning_rate": 3.789102152573665e-07,
      "loss": 0.9596,
      "step": 481
    },
    {
      "epoch": 1.951417004048583,
      "grad_norm": 0.0,
      "learning_rate": 3.228885936056858e-07,
      "loss": 0.9634,
      "step": 482
    },
    {
      "epoch": 1.9554655870445345,
      "grad_norm": 0.0,
      "learning_rate": 2.713394465242991e-07,
      "loss": 0.9619,
      "step": 483
    },
    {
      "epoch": 1.9595141700404857,
      "grad_norm": 0.0,
      "learning_rate": 2.242650870040497e-07,
      "loss": 0.9596,
      "step": 484
    },
    {
      "epoch": 1.9635627530364372,
      "grad_norm": 0.0,
      "learning_rate": 1.8166762725381203e-07,
      "loss": 0.9773,
      "step": 485
    },
    {
      "epoch": 1.9676113360323888,
      "grad_norm": 0.0,
      "learning_rate": 1.4354897860558992e-07,
      "loss": 0.9575,
      "step": 486
    },
    {
      "epoch": 1.97165991902834,
      "grad_norm": 0.0,
      "learning_rate": 1.0991085142886271e-07,
      "loss": 0.9505,
      "step": 487
    },
    {
      "epoch": 1.9757085020242915,
      "grad_norm": 0.0,
      "learning_rate": 8.075475505373575e-08,
      "loss": 0.9865,
      "step": 488
    },
    {
      "epoch": 1.979757085020243,
      "grad_norm": 0.0,
      "learning_rate": 5.608199770334999e-08,
      "loss": 0.9465,
      "step": 489
    },
    {
      "epoch": 1.9838056680161942,
      "grad_norm": 0.0,
      "learning_rate": 3.5893686435029e-08,
      "loss": 0.946,
      "step": 490
    },
    {
      "epoch": 1.9878542510121457,
      "grad_norm": 0.0,
      "learning_rate": 2.019072709074088e-08,
      "loss": 0.958,
      "step": 491
    },
    {
      "epoch": 1.9919028340080973,
      "grad_norm": 0.0,
      "learning_rate": 8.973824256364171e-09,
      "loss": 0.9399,
      "step": 492
    },
    {
      "epoch": 1.9959514170040484,
      "grad_norm": 0.0,
      "learning_rate": 2.2434812301352913e-09,
      "loss": 0.9116,
      "step": 493
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0,
      "learning_rate": 0.0,
      "loss": 0.9969,
      "step": 494
    }
  ],
  "logging_steps": 1,
  "max_steps": 494,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.9112171976175124e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
